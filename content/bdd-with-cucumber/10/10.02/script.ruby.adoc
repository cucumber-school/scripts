
=== Hunt for the bug
Good. Now let's run our improved scenario, using the `@todo` tag, and go hunting for that bug:

shot::[1, run `cucumber --tags @todo`]

OK, well we can see our scenario failing, but where do we need to go to fix it?

Luckily, our system is pretty small, and we remember that all the premium account behaviour is implemented in the `Network` class, so let's go and look there.

shot::[2, open the Network class]

Well, that `broadcast` method is pretty complex, but I suppose the bug must be in there somewhere. Let's try to pin it down with a unit test.

shot::[3, open the unit tests for Network]

Oh dear, oh dear: This file hardly contains any tests for the premium account behaviour! There's a test here for the behaviour around charging for long messages, but nothing for what happens when you mention the word "buy".

It looks like when that so-called "hot-shot ninja rockstar" subcontractor, Stevie, hacked in the first version of premium accounts, he tested almost everything from that one great big Cucumber scenario - the one we refactored in Chapter 7 - and didn't write enough unit tests.

==== The value of unit tests
[GoAnimate]
Why is this a problem?

Think about each automated test you write as warning light that you're fitting to your system. Acceptance tests are warning lights that make sense to business people: when they fail, they tell you what functionality a user will not be able to enjoy because of the bug.

What a unit test does is give the programmers an indication about why the bug has occurred. Ideally, whenever you see an acceptance test's warning light flash, there should be at least one corresponding unit test flashing too, pointing the developers to the source of the problem.

If you don't have any unit tests, you're left guessing where the problem lies. In a big system, this can be a serious waste of time.

