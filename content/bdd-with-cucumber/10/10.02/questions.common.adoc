==== Lesson 2 - Questions

===== What are the characteristics of a test suite that follows the *testing ice cream cone* anti-pattern?

* There are a relatively small number of unit tests (*Correct*)
* All of the tests run through Cucumber
* Most of the tests run through the full application stack (*Correct*)
* There are almost no integration tests
* Most of the tests are low-level unit tests

Explanation:

The testing ice-cream-cone represents an *inversion* of the testing pyramid. This means that you have only a small number of unit tests, 
and most of the testing is done through full-stack integration tests. You might be using Cucumber for those integration tests, or you might 
not; that's not important.

===== Which is better? Why?

* The testing ice cream cone is better because ice cream is tasty
* The testing pyramid is better because each test is at the lowest level possible (*Correct*)
* The testing diamond is better because you can never have too many integration tests
* The testing hourgrlass is better because it's more balanced, as all things should be in life

Explanation:

The testing pyramid represents a model for the ideal distribution of different types of tests. The idea here is that every behaviour you have in your system should have a low-level unit
test, and the key behaviours of bigger chunks of the system should have integration tests to check that those units wire together correctly.

Unit tests tend to be fast, and when they fail they give you a good pointer to the problem because they only cover a small amount of code.

But they're not enough on their own, because you might have lots of little units that all work OK on their own, but don't play nicely together. That's why you need a few integration tests too. 

But only a few!

The hourglass and diamond are not really well-known patterns in the industry. It's certainly possible that your test suite might look like that, but we don't recomment it!

===== What are the disadvantages of having a testing ice cream cone?

* You have so many scenarios, some describing quite obscure edge-cases, that they end up making poor documentation (*Correct*)
* The tests run too fast
* Because so many tests are full integration tests, the whole suite is slow to run (*Correct*)
* It's impossible to debug a failing Cucumber scenario
* When a test fails, there's too much code to search through to try and find the cause of the problem (*Correct*)
* The internal design of the code tends to be tangled like a plate of spaghetti because there was no need to make it modular for unit testing (*Correct*)

Explanation:

It's not impossible to debug a failling Cucumber scenario, but it's like having a warning light on your car's dashboard that just says "Something is wrong!". It's useful
for sure to know what _something_ is wrong, but more more useful to have a warning light specifically that the oil is low, or the brakes are not working. Then the mechanic
knows what they need to do to fix it.